{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5448a8",
   "metadata": {},
   "source": [
    "Create a Combined & Clean Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71c7bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total training images: 1900\n",
      "                                               Image  \\\n",
      "0  E:/OCR_project/Datasets/archive/Validate_deske...   \n",
      "1  E:/OCR_project/Datasets/archive/Validate_deske...   \n",
      "2  E:/OCR_project/Datasets/archive/Validate_deske...   \n",
      "3  E:/OCR_project/Datasets/archive/Validate_deske...   \n",
      "4  E:/OCR_project/Datasets/archive/Validate_deske...   \n",
      "\n",
      "                                                Text  \n",
      "0  Ø·ÙÙ†Ø§ ÙˆØ³Ø¹ÙŠÙ†Ø§ Ù…Ø¹ Ø´ÙŠØ®. ÙƒØ§Ù† Ø¬Ø§Ø±ÙŠ ÙÙŠ Ø§Ù„Ø®ÙŠÙ… ÙŠØªÙƒÙ„Ù… ÙˆÙ‡...  \n",
      "1  ÙØ¥Ù† Ø§Ù„Ù„Ù‡ ØªØ¹Ø§Ù„Ù‰ Ø®Ù„Ù‚ Ø§Ù„Ø®Ù„Ù‚ Ø¨Ø±Ø­Ù…ØªÙ‡ØŒ ÙˆÙ…Ù† Ø¹Ù„Ù‰ Ø¹Ø¨Ø§Ø¯Ù‡...  \n",
      "2  Ù…Ø§ ÙŠÙ‚Ø¯Ø±ÙˆÙ† Ø¨Ù‡ Ø¹Ù„Ù‰ Ø¥ØµØ­ Ù…Ø¹Ø§ÙŠØ´Ù‡Ù… ÙÙŠ Ø§Ù„Ø¯Ù†ÙŠØ§ØŒ ÙˆÙŠØ¯Ø±ÙƒÙˆ...  \n",
      "3  Ù…Ù† Ø§Ù„Ø¹Ø°Ø§Ø¨ ÙÙŠ Ø§Ø®Ø±ØŒ ÙˆØ£ÙØ¶Ù„ Ù…Ø§ Ø±Ø²Ù‚Ù‡Ù… Ø§Ù„Ù„Ù‡ ØªØ¹Ø§Ù„Ù‰ ÙˆÙ…...  \n",
      "4  Ù„Ø¬Ù…ÙŠØ¹ Ø§Ø´ÙŠØ§Ø¡ ÙˆØ§Ù„Ø°ÙŠ  ÙŠÙ‚Ø¯Ø± Ø£Ø­Ø¯ ÙÙŠ Ø§Ù„Ø¯Ù†ÙŠØ§ Ø¹Ù„Ù‰ Ø¥ØµØ­ ...  \n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Adjust these paths\n",
    "# train_images_path = \"E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed/\"\n",
    "# val_images_path = \"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "\n",
    "# # Load CSVs and drop row 0 if it's fake (123456789 row)\n",
    "# train_df = pd.read_csv(\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\")\n",
    "# val_df = pd.read_csv(\"E:/OCR_project/Datasets/archive/data_Set_converting/ValidateLabels.csv\")\n",
    "\n",
    "# # Drop fake row (index 1 in your case)\n",
    "# train_df = train_df.iloc[2:].reset_index(drop=True)\n",
    "# val_df = val_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# # Add full path to each image\n",
    "# train_df[\"Image\"] = train_df[\"Image\"].apply(lambda x: os.path.join(train_images_path, x))\n",
    "# val_df[\"Image\"] = val_df[\"Image\"].apply(lambda x: os.path.join(val_images_path, x))\n",
    "\n",
    "# # Sort for consistency\n",
    "# train_df = train_df.sort_values(\"Image\").reset_index(drop=True)\n",
    "# val_df = val_df.sort_values(\"Image\").reset_index(drop=True)\n",
    "\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Paths\n",
    "# train_images_path = r\"E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed\"\n",
    "# val_images_path = r\"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "\n",
    "# train_csv_path = r\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"\n",
    "# val_csv_path = r\"E:/OCR_project/Datasets/archive/data_Set_converting/ValidateLabels.csv\"\n",
    "\n",
    "# # Load CSVs\n",
    "# train_df = pd.read_csv(train_csv_path)\n",
    "# val_df = pd.read_csv(val_csv_path)\n",
    "\n",
    "# # Remove invalid rows (where Image column is not a real filename)\n",
    "# valid_ext = ('.jpg', '.jpeg', '.png')\n",
    "# train_df = train_df[train_df[\"Image\"].str.lower().str.endswith(valid_ext)].reset_index(drop=True)\n",
    "# val_df = val_df[val_df[\"Image\"].str.lower().str.endswith(valid_ext)].reset_index(drop=True)\n",
    "\n",
    "# # Add full path to images\n",
    "# train_df[\"Image\"] = train_df[\"Image\"].apply(lambda x: os.path.join(train_images_path, x))\n",
    "# val_df[\"Image\"] = val_df[\"Image\"].apply(lambda x: os.path.join(val_images_path, x))\n",
    "\n",
    "# # Sort for consistency\n",
    "# train_df = train_df.sort_values(\"Image\").reset_index(drop=True)\n",
    "# val_df = val_df.sort_values(\"Image\").reset_index(drop=True)\n",
    "\n",
    "# # Optional: quick check\n",
    "# print(f\"âœ… Train images: {len(train_df)}\")\n",
    "# print(f\"âœ… Validation images: {len(val_df)}\")\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths (using your provided ones)\n",
    "IMG_DIR = r\"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "csv_path = r\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Keep only valid image rows\n",
    "valid_ext = ('.jpg', '.jpeg', '.png')\n",
    "df = df[df[\"Image\"].str.lower().str.endswith(valid_ext)].reset_index(drop=True)\n",
    "\n",
    "# Add full path to images\n",
    "df[\"Image\"] = df[\"Image\"].apply(lambda x: os.path.join(IMG_DIR, x))\n",
    "\n",
    "# Sort for consistency\n",
    "df = df.sort_values(\"Image\").reset_index(drop=True)\n",
    "\n",
    "# Final check\n",
    "print(f\"âœ… Total training images: {len(df)}\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ec5a1",
   "metadata": {},
   "source": [
    "Extract Character Set and Max Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d3f85e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Unique characters: [' ', '\"', '#', '%', '(', ')', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', '_', 'ØŒ', 'Ø¡', 'Ø¢', 'Ø£', 'Ø¤', 'Ø¥', 'Ø¦', 'Ø§', 'Ø¨', 'Øª', 'Ø«', 'Ø¬', 'Ø­', 'Ø®', 'Ø¯', 'Ø°', 'Ø±', 'Ø²', 'Ø³', 'Ø´', 'Øµ', 'Ø¶', 'Ø·', 'Ø¸', 'Ø¹', 'Øº', 'Ù', 'Ù‚', 'Ùƒ', 'Ù„', 'Ù…', 'Ù†', 'Ù‡', 'Ùˆ', 'Ù‰', 'ÙŠ']\n",
      "âœ… Max text length: 109\n"
     ]
    }
   ],
   "source": [
    "# Get all unique characters in training set\n",
    "characters = set(char for text in df[\"Text\"] for char in text)\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "# Find maximum label length\n",
    "max_length = df[\"Text\"].apply(len).max()\n",
    "\n",
    "print(\"âœ… Unique characters:\", characters)\n",
    "print(\"âœ… Max text length:\", max_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e622443f",
   "metadata": {},
   "source": [
    "Prepare Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aec1d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_path = train_df[\"Image\"].values\n",
    "# y_train = train_df[\"Text\"].values\n",
    "\n",
    "# X_val_path = val_df[\"Image\"].values\n",
    "# y_val = val_df[\"Text\"].values\n",
    "# Training data\n",
    "X_train_path = df[\"Image\"].values\n",
    "y_train = df[\"Text\"].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68197e88",
   "metadata": {},
   "source": [
    " Define Char Map for CTC  (Connectionist Temporal Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfae0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Character â†” number mapping\n",
    "char_to_num = layers.StringLookup(vocabulary=characters, mask_token=None)\n",
    "num_to_char = layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ced1ee",
   "metadata": {},
   "source": [
    "Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d41b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_free_resize(image, img_size):\n",
    "    w, h = img_size\n",
    "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
    "    pad_height = h - tf.shape(image)[0]\n",
    "    pad_width = w - tf.shape(image)[1]\n",
    "\n",
    "    pad_height_top = pad_height // 2 + pad_height % 2\n",
    "    pad_height_bottom = pad_height // 2\n",
    "    pad_width_left = pad_width // 2 + pad_width % 2\n",
    "    pad_width_right = pad_width // 2\n",
    "\n",
    "    image = tf.pad(image, paddings=[\n",
    "        [pad_height_top, pad_height_bottom],\n",
    "        [pad_width_left, pad_width_right],\n",
    "        [0, 0],\n",
    "    ])\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    return image\n",
    "\n",
    "image_width = 2882\n",
    "image_height = 46\n",
    "padding_token = 99\n",
    "batch_size = 64\n",
    "\n",
    "def preprocess_image(image_path, img_size=(image_width, image_height)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=1)\n",
    "    image = distortion_free_resize(image, img_size)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "def vectorize_label(label):\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = 128 - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
    "    return label\n",
    "\n",
    "def process_images_labels(image_path, label):\n",
    "    image = preprocess_image(image_path)\n",
    "    label = vectorize_label(label)\n",
    "    return {\"image\": image, \"label\": label}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819232eb",
   "metadata": {},
   "source": [
    "Create Datasets by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "188685f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(image_paths, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(process_images_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = prepare_dataset(X_train_path, y_train)\n",
    "# validation_ds = prepare_dataset(X_val_path, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733fd8b",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b95aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Custom CTC Layer\n",
    "class CTCLayer(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        return y_pred  # At test time, just return predictions\n",
    "\n",
    "# Build Model Function\n",
    "def build_model():\n",
    "    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n",
    "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
    "\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"Conv1\")(input_img)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    new_shape = ((image_width // 2), (image_height // 2) * 64)\n",
    "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "\n",
    "    x = keras.layers.Dense(16, activation=\"relu\", name=\"dense2\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(128, return_sequences=True, dropout=0.35)\n",
    "    )(x)\n",
    "\n",
    "    x = keras.layers.Dense(\n",
    "        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense3\"\n",
    "    )(x)\n",
    "\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input_img, labels], outputs=output, name=\"Arabic_OCR\")\n",
    "\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.0001,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9\n",
    "    )\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# Edit Distance Calculation Function\n",
    "def calculate_edit_distance(labels, predictions):\n",
    "    sparse_labels = tf.sparse.from_dense(labels)\n",
    "\n",
    "    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n",
    "\n",
    "    decoded_preds = keras.backend.ctc_decode(\n",
    "        predictions, input_length=input_len, greedy=False, beam_width=100\n",
    "    )[0][0][:, :max_length]\n",
    "\n",
    "    sparse_preds = tf.sparse.from_dense(decoded_preds)\n",
    "\n",
    "    edit_distances = tf.edit_distance(sparse_preds, sparse_labels, normalize=False)\n",
    "    return tf.reduce_mean(edit_distances)\n",
    "\n",
    "# Custom Callback to Print Edit Distance\n",
    "# class EditDistanceCallback(keras.callbacks.Callback):\n",
    "#     def __init__(self, pred_model):\n",
    "#         super().__init__()\n",
    "#         self.prediction_model = pred_model\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         edit_distances = []\n",
    "\n",
    "#         for i in range(len(validation_images)):\n",
    "#             labels = validation_labels[i]\n",
    "#             predictions = self.prediction_model.predict(validation_images[i])\n",
    "#             edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n",
    "\n",
    "#         print(f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\")\n",
    "#***********************************************************************\n",
    "class EditDistanceCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, pred_model, val_images=None, val_labels=None):\n",
    "        super().__init__()\n",
    "        self.prediction_model = pred_model\n",
    "        self.val_images = val_images\n",
    "        self.val_labels = val_labels\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if not self.val_images or not self.val_labels:\n",
    "            return  # skip if no validation data\n",
    "        edit_distances = []\n",
    "        for i in range(len(self.val_images)):\n",
    "            labels = self.val_labels[i]\n",
    "            predictions = self.prediction_model.predict(self.val_images[i])\n",
    "            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n",
    "        print(f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47cb7cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n",
      "Conv1\n",
      "pool1\n",
      "batch_normalization_4\n",
      "reshape\n",
      "dense2\n",
      "batch_normalization_5\n",
      "bidirectional_2\n",
      "label\n",
      "dense3\n",
      "ctc_loss\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d67854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m16:02\u001b[0m 33s/step - loss: 334656.5625"
     ]
    }
   ],
   "source": [
    "# 1. Build the model\n",
    "model = build_model()\n",
    "\n",
    "# 2. Extract prediction model from the full model (before CTCLayer)\n",
    "# CTCLayer is the final output, so we skip it in prediction\n",
    "# prediction_model = keras.models.Model(\n",
    "#     model.get_layer(name=\"image\").input,  # âœ… This is the input layer\n",
    "#     model.get_layer(name=\"dense3\").output # âœ… This is the layer before CTCLayer\n",
    "# )\n",
    "prediction_model = keras.models.Model(\n",
    "    model.input,\n",
    "    model.get_layer(name=\"dense3\").output\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Create the custom callback\n",
    "edit_distance_callback = EditDistanceCallback(prediction_model)\n",
    "\n",
    "# 4. Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[edit_distance_callback],\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdbf4042",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m missing_files \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(IMG_DIR, x)))]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal missing images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(missing_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(missing_files\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "missing_files = df[~df[\"filename\"].apply(lambda x: os.path.exists(os.path.join(IMG_DIR, x)))]\n",
    "print(f\"Total missing images: {len(missing_files)}\")\n",
    "print(missing_files.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f243fe",
   "metadata": {},
   "source": [
    "fixing problem why can`t see images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cfd87",
   "metadata": {},
   "source": [
    "| Issue                                                        | Fix                                             |\n",
    "| ------------------------------------------------------------ | ----------------------------------------------- |\n",
    "| Extra spaces in filename                                     | Strip whitespace: `x.strip()`                   |\n",
    "| Wrong case (Windows is case-insensitive, but safer to check) | Ensure file names are exact                     |\n",
    "| Wrong column name                                            | Confirm `Image` column has the filenames        |\n",
    "| Double slashes or backslashes                                | Use `os.path.join()` instead of manual paths    |\n",
    "| Encoding issues from CSV                                     | Open CSV in `utf-8` or `windows-1256` if Arabic |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4197dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Total missing image files: 1901\n",
      "                    Image                                               Text\n",
      "0                       0                                          123456789\n",
      "1  AHTD3A0001_Para1_3.jpg  Ø·ÙÙ†Ø§ ÙˆØ³Ø¹ÙŠÙ†Ø§ Ù…Ø¹ Ø´ÙŠØ®. ÙƒØ§Ù† Ø¬Ø§Ø±ÙŠ ÙÙŠ Ø§Ù„Ø®ÙŠÙ… ÙŠØªÙƒÙ„Ù… ÙˆÙ‡...\n",
      "2  AHTD3A0005_Para1_1.jpg  Ø°Ù‡Ø¨ Ù†ÙˆØ­ Ù…Ø¸ÙØ± Ø¶Ø±ØºØ§Ù… Ø¨ØµØ­ Ø¨ Ø±Ø¤ÙˆÙ Ø¨Ù† Ù„Ø¤ÙŠ Ø±Ø§ÙŠÙ‚ Ø¸Ø§ÙØ±...\n",
      "3  AHTD3A0005_Para1_2.jpg  Ø¨Ø¯Ø£Øª Ù‚ÙˆØ§ÙÙ„ Ø§Ù„Ø­Ø¬ÙŠØ¬ Ø­Ø§Ø¬ Ø§Ø«Ø± Ø§Ø®Ø± ÙŠÙ„Ø¨ÙŠ. Ø¹Ù†Ø¯ ÙˆØµÙˆÙ„Ù†Ø§...\n",
      "4  AHTD3A0005_Para1_3.jpg  ÙŠØªÙƒÙ„Ù… ÙˆÙ‡Ùˆ Ù†Ø§Ø¦Ù…  Ø¨ÙƒÙ„Ù…Ø§Øª Ù„Ø§ Ø£ÙÙ‡Ù…Ù‡Ø§ Ù…Ø«Ù„ Ø§Ù†Ù‚Ø¶ Ø¨ØºÙ„Ø³...\n",
      "5  AHTD3A0047_Para1_1.jpg  Ø°Ù‡Ø¨ Ù†ÙˆØ­ Ù…Ø¸ÙØ± Ø¶Ø±ØºØ§Ù… Ø¨ØµØ­Ø¨ Ø±Ø¤ÙˆÙ Ø¨Ù† Ù„Ø¤ÙŠ Ø±Ø§ÙŠÙ‚ Ø¸Ø§ÙØ± ...\n",
      "6  AHTD3A0047_Para1_2.jpg  Ø¨Ø¯Ø£Øª Ù‚ÙˆØ§ÙÙ„ Ø§Ù„Ø­Ø¬ÙŠØ¬ Ø­Ø§Ø¬ Ø¥Ø«Ø± Ø¢Ø®Ø± ÙŠÙ„Ø¨ÙŠ Ø¹Ù†Ø¯ ÙˆØµÙˆÙ„Ù†Ø§ ...\n",
      "7  AHTD3A0047_Para1_3.jpg  ÙŠØªÙƒÙ„Ù… ÙÙŠ Ø§Ù„Ø®ÙŠÙ… ÙŠØªÙƒÙ„Ù… ÙˆÙ‡Ùˆ Ù†Ø§Ø¦Ù…  Ø¨ÙƒÙ„Ù…Ø§Øª Ù„Ø§ Ø£ÙÙ‡Ù…Ù‡...\n",
      "8  AHTD3A0047_Para1_4.jpg  Ø±Ø§Ø¬Ø­ Ù‡Ù„ Ø¨Ù„Øº Ø£ØµØ­Ø§Ø¨Ù†Ø§ Ø¸ Ø¹ Ùƒ  Ø« Ø® Ø¶ Ø¨ Ø³ Ø´ Øµ Øº Ù‡ Ø£...\n",
      "9  AHTD3A0047_Para1_5.jpg  Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ù…Ø´Ù…Ø´ Ø¯Ø±Ø§Ù‚ ØºÙŠØ¸ Ù†Ø§Ø¡   Ø¨...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set image directory and load CSV\n",
    "IMG_DIR = \"E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed/\"\n",
    "csv_path = \"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"  # Adjust if needed\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Find missing files\n",
    "missing_files = df[~df[\"Image\"].apply(lambda x: os.path.exists(os.path.join(IMG_DIR, x)))]\n",
    "\n",
    "# Print report\n",
    "print(f\"âŒ Total missing image files: {len(missing_files)}\")\n",
    "print(missing_files.head(10))  # Show first 10 missing\n",
    "\n",
    "# Optional: Save list of missing to a CSV file for review\n",
    "missing_files.to_csv(\"missing_files_report.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918bcdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few mismatches:\n",
      "CSV: '0'  â†’  Exists: False\n",
      "CSV: 'AHTD3A0001_Para1_3.jpg'  â†’  Exists: False\n",
      "CSV: 'AHTD3A0005_Para1_1.jpg'  â†’  Exists: False\n",
      "CSV: 'AHTD3A0005_Para1_2.jpg'  â†’  Exists: False\n",
      "CSV: 'AHTD3A0005_Para1_3.jpg'  â†’  Exists: False\n",
      "CSV: 'AHTD3A0047_Para1_1.jpg'  â†’  Exists: False\n",
      "CSV: 'AHTD3A0047_Para1_2.jpg'  â†’  Exists: False\n",
      "CSV: 'AHTD3A0047_Para1_3.jpg'  â†’  Exists: False\n",
      "CSV: 'AHTD3A0047_Para1_4.jpg'  â†’  Exists: False\n",
      "CSV: 'AHTD3A0047_Para1_5.jpg'  â†’  Exists: False\n"
     ]
    }
   ],
   "source": [
    "# Show first 5 mismatches with actual directory files\n",
    "all_images = set(os.listdir(IMG_DIR))\n",
    "print(\"First few mismatches:\")\n",
    "for name in df[\"Image\"].head(10):\n",
    "    print(f\"CSV: '{name}'  â†’  Exists: {name in all_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c1cf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 9522\n",
      "Sample: ['AHTD3A0008_Para1_1.jpg', 'AHTD3A0008_Para1_5.jpg', 'AHTD3A0008_Para1_6.jpg', 'AHTD3A0008_Para2_1.jpg', 'AHTD3A0008_Para2_2.jpg', 'AHTD3A0008_Para2_3.jpg', 'AHTD3A0008_Para2_4.jpg', 'AHTD3A0008_Para2_5.jpg', 'AHTD3A0008_Para2_6.jpg', 'AHTD3A0008_Para3_1.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "IMG_DIR = r\"E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed\"\n",
    "\n",
    "# List a few files from your directory\n",
    "files = os.listdir(IMG_DIR)\n",
    "print(f\"Total files found: {len(files)}\")\n",
    "print(\"Sample:\", files[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960b032e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found at: E:/OCR_project/Datasets/archive\\Validate_deskewed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = r\"E:/OCR_project/Datasets/archive\"\n",
    "search_name = \"AHTD3A0001_Para1_3.jpg\"\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    if search_name in filenames:\n",
    "        print(\"Found at:\", dirpath)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49fda65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Total missing image files: 1\n",
      "  Image       Text\n",
      "0     0  123456789\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "IMG_DIR = r\"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "csv_path = r\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "df[\"Image\"] = df[\"Image\"].astype(str).str.strip()\n",
    "\n",
    "# Check missing\n",
    "missing_files = df[~df[\"Image\"].apply(lambda x: os.path.exists(os.path.join(IMG_DIR, x)))]\n",
    "\n",
    "print(f\"âŒ Total missing image files: {len(missing_files)}\")\n",
    "print(missing_files.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6f0224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¼ Images in folder: 1905\n",
      "ğŸ“„ Rows in CSV: 1901\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "IMG_DIR = r\"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "csv_path = r\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"\n",
    "\n",
    "# Count images in directory\n",
    "image_count = len([f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "# Count rows in CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "csv_count = len(df)\n",
    "\n",
    "print(f\"ğŸ–¼ Images in folder: {image_count}\")\n",
    "print(f\"ğŸ“„ Rows in CSV: {csv_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e8d629f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image    1901\n",
       "Text     1901\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
