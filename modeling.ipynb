{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5448a8",
   "metadata": {},
   "source": [
    "Create a Combined & Clean Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71c7bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total training images: 1900\n",
      "                                               Image  \\\n",
      "0  E:/OCR_project/Datasets/archive/Validate_deske...   \n",
      "1  E:/OCR_project/Datasets/archive/Validate_deske...   \n",
      "2  E:/OCR_project/Datasets/archive/Validate_deske...   \n",
      "3  E:/OCR_project/Datasets/archive/Validate_deske...   \n",
      "4  E:/OCR_project/Datasets/archive/Validate_deske...   \n",
      "\n",
      "                                                Text  \n",
      "0  طفنا وسعينا مع شيخ. كان جاري في الخيم يتكلم وه...  \n",
      "1  فإن الله تعالى خلق الخلق برحمته، ومن على عباده...  \n",
      "2  ما يقدرون به على إصح معايشهم في الدنيا، ويدركو...  \n",
      "3  من العذاب في اخر، وأفضل ما رزقهم الله تعالى وم...  \n",
      "4  لجميع اشياء والذي  يقدر أحد في الدنيا على إصح ...  \n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Adjust these paths\n",
    "# train_images_path = \"E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed/\"\n",
    "# val_images_path = \"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "\n",
    "# # Load CSVs and drop row 0 if it's fake (123456789 row)\n",
    "# train_df = pd.read_csv(\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\")\n",
    "# val_df = pd.read_csv(\"E:/OCR_project/Datasets/archive/data_Set_converting/ValidateLabels.csv\")\n",
    "\n",
    "# # Drop fake row (index 1 in your case)\n",
    "# train_df = train_df.iloc[2:].reset_index(drop=True)\n",
    "# val_df = val_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# # Add full path to each image\n",
    "# train_df[\"Image\"] = train_df[\"Image\"].apply(lambda x: os.path.join(train_images_path, x))\n",
    "# val_df[\"Image\"] = val_df[\"Image\"].apply(lambda x: os.path.join(val_images_path, x))\n",
    "\n",
    "# # Sort for consistency\n",
    "# train_df = train_df.sort_values(\"Image\").reset_index(drop=True)\n",
    "# val_df = val_df.sort_values(\"Image\").reset_index(drop=True)\n",
    "\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Paths\n",
    "# train_images_path = r\"E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed\"\n",
    "# val_images_path = r\"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "\n",
    "# train_csv_path = r\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"\n",
    "# val_csv_path = r\"E:/OCR_project/Datasets/archive/data_Set_converting/ValidateLabels.csv\"\n",
    "\n",
    "# # Load CSVs\n",
    "# train_df = pd.read_csv(train_csv_path)\n",
    "# val_df = pd.read_csv(val_csv_path)\n",
    "\n",
    "# # Remove invalid rows (where Image column is not a real filename)\n",
    "# valid_ext = ('.jpg', '.jpeg', '.png')\n",
    "# train_df = train_df[train_df[\"Image\"].str.lower().str.endswith(valid_ext)].reset_index(drop=True)\n",
    "# val_df = val_df[val_df[\"Image\"].str.lower().str.endswith(valid_ext)].reset_index(drop=True)\n",
    "\n",
    "# # Add full path to images\n",
    "# train_df[\"Image\"] = train_df[\"Image\"].apply(lambda x: os.path.join(train_images_path, x))\n",
    "# val_df[\"Image\"] = val_df[\"Image\"].apply(lambda x: os.path.join(val_images_path, x))\n",
    "\n",
    "# # Sort for consistency\n",
    "# train_df = train_df.sort_values(\"Image\").reset_index(drop=True)\n",
    "# val_df = val_df.sort_values(\"Image\").reset_index(drop=True)\n",
    "\n",
    "# # Optional: quick check\n",
    "# print(f\"✅ Train images: {len(train_df)}\")\n",
    "# print(f\"✅ Validation images: {len(val_df)}\")\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths (using your provided ones)\n",
    "IMG_DIR = r\"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "csv_path = r\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Keep only valid image rows\n",
    "valid_ext = ('.jpg', '.jpeg', '.png')\n",
    "df = df[df[\"Image\"].str.lower().str.endswith(valid_ext)].reset_index(drop=True)\n",
    "\n",
    "# Add full path to images\n",
    "df[\"Image\"] = df[\"Image\"].apply(lambda x: os.path.join(IMG_DIR, x))\n",
    "\n",
    "# Sort for consistency\n",
    "df = df.sort_values(\"Image\").reset_index(drop=True)\n",
    "\n",
    "# Final check\n",
    "print(f\"✅ Total training images: {len(df)}\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ec5a1",
   "metadata": {},
   "source": [
    "Extract Character Set and Max Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d3f85e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Unique characters: [' ', '\"', '#', '%', '(', ')', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', '_', '،', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي']\n",
      "✅ Max text length: 109\n"
     ]
    }
   ],
   "source": [
    "# Get all unique characters in training set\n",
    "characters = set(char for text in df[\"Text\"] for char in text)\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "# Find maximum label length\n",
    "max_length = df[\"Text\"].apply(len).max()\n",
    "\n",
    "print(\"✅ Unique characters:\", characters)\n",
    "print(\"✅ Max text length:\", max_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e622443f",
   "metadata": {},
   "source": [
    "Prepare Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aec1d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_path = train_df[\"Image\"].values\n",
    "# y_train = train_df[\"Text\"].values\n",
    "\n",
    "# X_val_path = val_df[\"Image\"].values\n",
    "# y_val = val_df[\"Text\"].values\n",
    "# Training data\n",
    "X_train_path = df[\"Image\"].values\n",
    "y_train = df[\"Text\"].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68197e88",
   "metadata": {},
   "source": [
    " Define Char Map for CTC  (Connectionist Temporal Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfae0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Character ↔ number mapping\n",
    "char_to_num = layers.StringLookup(vocabulary=characters, mask_token=None)\n",
    "num_to_char = layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ced1ee",
   "metadata": {},
   "source": [
    "Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d41b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_free_resize(image, img_size):\n",
    "    w, h = img_size\n",
    "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
    "    pad_height = h - tf.shape(image)[0]\n",
    "    pad_width = w - tf.shape(image)[1]\n",
    "\n",
    "    pad_height_top = pad_height // 2 + pad_height % 2\n",
    "    pad_height_bottom = pad_height // 2\n",
    "    pad_width_left = pad_width // 2 + pad_width % 2\n",
    "    pad_width_right = pad_width // 2\n",
    "\n",
    "    image = tf.pad(image, paddings=[\n",
    "        [pad_height_top, pad_height_bottom],\n",
    "        [pad_width_left, pad_width_right],\n",
    "        [0, 0],\n",
    "    ])\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    return image\n",
    "\n",
    "image_width = 2882\n",
    "image_height = 46\n",
    "padding_token = 99\n",
    "batch_size = 64\n",
    "\n",
    "def preprocess_image(image_path, img_size=(image_width, image_height)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=1)\n",
    "    image = distortion_free_resize(image, img_size)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "def vectorize_label(label):\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = 128 - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
    "    return label\n",
    "\n",
    "def process_images_labels(image_path, label):\n",
    "    image = preprocess_image(image_path)\n",
    "    label = vectorize_label(label)\n",
    "    return {\"image\": image, \"label\": label}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819232eb",
   "metadata": {},
   "source": [
    "Create Datasets by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "188685f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(image_paths, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(process_images_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = prepare_dataset(X_train_path, y_train)\n",
    "# validation_ds = prepare_dataset(X_val_path, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733fd8b",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b95aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Custom CTC Layer\n",
    "class CTCLayer(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        return y_pred  # At test time, just return predictions\n",
    "\n",
    "# Build Model Function\n",
    "def build_model():\n",
    "    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n",
    "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
    "\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"Conv1\")(input_img)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    new_shape = ((image_width // 2), (image_height // 2) * 64)\n",
    "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "\n",
    "    x = keras.layers.Dense(16, activation=\"relu\", name=\"dense2\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(128, return_sequences=True, dropout=0.35)\n",
    "    )(x)\n",
    "\n",
    "    x = keras.layers.Dense(\n",
    "        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense3\"\n",
    "    )(x)\n",
    "\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input_img, labels], outputs=output, name=\"Arabic_OCR\")\n",
    "\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.0001,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9\n",
    "    )\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# Edit Distance Calculation Function\n",
    "def calculate_edit_distance(labels, predictions):\n",
    "    sparse_labels = tf.sparse.from_dense(labels)\n",
    "\n",
    "    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n",
    "\n",
    "    decoded_preds = keras.backend.ctc_decode(\n",
    "        predictions, input_length=input_len, greedy=False, beam_width=100\n",
    "    )[0][0][:, :max_length]\n",
    "\n",
    "    sparse_preds = tf.sparse.from_dense(decoded_preds)\n",
    "\n",
    "    edit_distances = tf.edit_distance(sparse_preds, sparse_labels, normalize=False)\n",
    "    return tf.reduce_mean(edit_distances)\n",
    "\n",
    "# Custom Callback to Print Edit Distance\n",
    "# class EditDistanceCallback(keras.callbacks.Callback):\n",
    "#     def __init__(self, pred_model):\n",
    "#         super().__init__()\n",
    "#         self.prediction_model = pred_model\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         edit_distances = []\n",
    "\n",
    "#         for i in range(len(validation_images)):\n",
    "#             labels = validation_labels[i]\n",
    "#             predictions = self.prediction_model.predict(validation_images[i])\n",
    "#             edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n",
    "\n",
    "#         print(f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\")\n",
    "#***********************************************************************\n",
    "class EditDistanceCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, pred_model, val_images=None, val_labels=None):\n",
    "        super().__init__()\n",
    "        self.prediction_model = pred_model\n",
    "        self.val_images = val_images\n",
    "        self.val_labels = val_labels\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if not self.val_images or not self.val_labels:\n",
    "            return  # skip if no validation data\n",
    "        edit_distances = []\n",
    "        for i in range(len(self.val_images)):\n",
    "            labels = self.val_labels[i]\n",
    "            predictions = self.prediction_model.predict(self.val_images[i])\n",
    "            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n",
    "        print(f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47cb7cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n",
      "Conv1\n",
      "pool1\n",
      "batch_normalization_4\n",
      "reshape\n",
      "dense2\n",
      "batch_normalization_5\n",
      "bidirectional_2\n",
      "label\n",
      "dense3\n",
      "ctc_loss\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d67854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:02\u001b[0m 33s/step - loss: 334656.5625"
     ]
    }
   ],
   "source": [
    "# 1. Build the model\n",
    "model = build_model()\n",
    "\n",
    "# 2. Extract prediction model from the full model (before CTCLayer)\n",
    "# CTCLayer is the final output, so we skip it in prediction\n",
    "# prediction_model = keras.models.Model(\n",
    "#     model.get_layer(name=\"image\").input,  # ✅ This is the input layer\n",
    "#     model.get_layer(name=\"dense3\").output # ✅ This is the layer before CTCLayer\n",
    "# )\n",
    "prediction_model = keras.models.Model(\n",
    "    model.input,\n",
    "    model.get_layer(name=\"dense3\").output\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Create the custom callback\n",
    "edit_distance_callback = EditDistanceCallback(prediction_model)\n",
    "\n",
    "# 4. Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[edit_distance_callback],\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdbf4042",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m missing_files \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(IMG_DIR, x)))]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal missing images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(missing_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(missing_files\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "missing_files = df[~df[\"filename\"].apply(lambda x: os.path.exists(os.path.join(IMG_DIR, x)))]\n",
    "print(f\"Total missing images: {len(missing_files)}\")\n",
    "print(missing_files.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f243fe",
   "metadata": {},
   "source": [
    "fixing problem why can`t see images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cfd87",
   "metadata": {},
   "source": [
    "| Issue                                                        | Fix                                             |\n",
    "| ------------------------------------------------------------ | ----------------------------------------------- |\n",
    "| Extra spaces in filename                                     | Strip whitespace: `x.strip()`                   |\n",
    "| Wrong case (Windows is case-insensitive, but safer to check) | Ensure file names are exact                     |\n",
    "| Wrong column name                                            | Confirm `Image` column has the filenames        |\n",
    "| Double slashes or backslashes                                | Use `os.path.join()` instead of manual paths    |\n",
    "| Encoding issues from CSV                                     | Open CSV in `utf-8` or `windows-1256` if Arabic |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4197dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Total missing image files: 1901\n",
      "                    Image                                               Text\n",
      "0                       0                                          123456789\n",
      "1  AHTD3A0001_Para1_3.jpg  طفنا وسعينا مع شيخ. كان جاري في الخيم يتكلم وه...\n",
      "2  AHTD3A0005_Para1_1.jpg  ذهب نوح مظفر ضرغام بصح ب رؤوف بن لؤي رايق ظافر...\n",
      "3  AHTD3A0005_Para1_2.jpg  بدأت قوافل الحجيج حاج اثر اخر يلبي. عند وصولنا...\n",
      "4  AHTD3A0005_Para1_3.jpg  يتكلم وهو نائم  بكلمات لا أفهمها مثل انقض بغلس...\n",
      "5  AHTD3A0047_Para1_1.jpg  ذهب نوح مظفر ضرغام بصحب رؤوف بن لؤي رايق ظافر ...\n",
      "6  AHTD3A0047_Para1_2.jpg  بدأت قوافل الحجيج حاج إثر آخر يلبي عند وصولنا ...\n",
      "7  AHTD3A0047_Para1_3.jpg  يتكلم في الخيم يتكلم وهو نائم  بكلمات لا أفهمه...\n",
      "8  AHTD3A0047_Para1_4.jpg  راجح هل بلغ أصحابنا ظ ع ك  ث خ ض ب س ش ص غ ه أ...\n",
      "9  AHTD3A0047_Para1_5.jpg  الكلمات التالي لهذا النص مشمش دراق غيظ ناء   ب...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set image directory and load CSV\n",
    "IMG_DIR = \"E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed/\"\n",
    "csv_path = \"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"  # Adjust if needed\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Find missing files\n",
    "missing_files = df[~df[\"Image\"].apply(lambda x: os.path.exists(os.path.join(IMG_DIR, x)))]\n",
    "\n",
    "# Print report\n",
    "print(f\"❌ Total missing image files: {len(missing_files)}\")\n",
    "print(missing_files.head(10))  # Show first 10 missing\n",
    "\n",
    "# Optional: Save list of missing to a CSV file for review\n",
    "missing_files.to_csv(\"missing_files_report.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918bcdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few mismatches:\n",
      "CSV: '0'  →  Exists: False\n",
      "CSV: 'AHTD3A0001_Para1_3.jpg'  →  Exists: False\n",
      "CSV: 'AHTD3A0005_Para1_1.jpg'  →  Exists: False\n",
      "CSV: 'AHTD3A0005_Para1_2.jpg'  →  Exists: False\n",
      "CSV: 'AHTD3A0005_Para1_3.jpg'  →  Exists: False\n",
      "CSV: 'AHTD3A0047_Para1_1.jpg'  →  Exists: False\n",
      "CSV: 'AHTD3A0047_Para1_2.jpg'  →  Exists: False\n",
      "CSV: 'AHTD3A0047_Para1_3.jpg'  →  Exists: False\n",
      "CSV: 'AHTD3A0047_Para1_4.jpg'  →  Exists: False\n",
      "CSV: 'AHTD3A0047_Para1_5.jpg'  →  Exists: False\n"
     ]
    }
   ],
   "source": [
    "# Show first 5 mismatches with actual directory files\n",
    "all_images = set(os.listdir(IMG_DIR))\n",
    "print(\"First few mismatches:\")\n",
    "for name in df[\"Image\"].head(10):\n",
    "    print(f\"CSV: '{name}'  →  Exists: {name in all_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c1cf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 9522\n",
      "Sample: ['AHTD3A0008_Para1_1.jpg', 'AHTD3A0008_Para1_5.jpg', 'AHTD3A0008_Para1_6.jpg', 'AHTD3A0008_Para2_1.jpg', 'AHTD3A0008_Para2_2.jpg', 'AHTD3A0008_Para2_3.jpg', 'AHTD3A0008_Para2_4.jpg', 'AHTD3A0008_Para2_5.jpg', 'AHTD3A0008_Para2_6.jpg', 'AHTD3A0008_Para3_1.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "IMG_DIR = r\"E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed\"\n",
    "\n",
    "# List a few files from your directory\n",
    "files = os.listdir(IMG_DIR)\n",
    "print(f\"Total files found: {len(files)}\")\n",
    "print(\"Sample:\", files[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960b032e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found at: E:/OCR_project/Datasets/archive\\Validate_deskewed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = r\"E:/OCR_project/Datasets/archive\"\n",
    "search_name = \"AHTD3A0001_Para1_3.jpg\"\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    if search_name in filenames:\n",
    "        print(\"Found at:\", dirpath)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49fda65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Total missing image files: 1\n",
      "  Image       Text\n",
      "0     0  123456789\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "IMG_DIR = r\"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "csv_path = r\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "df[\"Image\"] = df[\"Image\"].astype(str).str.strip()\n",
    "\n",
    "# Check missing\n",
    "missing_files = df[~df[\"Image\"].apply(lambda x: os.path.exists(os.path.join(IMG_DIR, x)))]\n",
    "\n",
    "print(f\"❌ Total missing image files: {len(missing_files)}\")\n",
    "print(missing_files.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6f0224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼 Images in folder: 1905\n",
      "📄 Rows in CSV: 1901\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "IMG_DIR = r\"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "csv_path = r\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"\n",
    "\n",
    "# Count images in directory\n",
    "image_count = len([f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "# Count rows in CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "csv_count = len(df)\n",
    "\n",
    "print(f\"🖼 Images in folder: {image_count}\")\n",
    "print(f\"📄 Rows in CSV: {csv_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e8d629f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image    1901\n",
       "Text     1901\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
