{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5448a8",
   "metadata": {},
   "source": [
    "Create a Combined & Clean Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71c7bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Adjust these paths\n",
    "train_images_path = \"E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed/\"\n",
    "val_images_path = \"E:/OCR_project/Datasets/archive/Validate_deskewed\"\n",
    "\n",
    "# Load CSVs and drop row 0 if it's fake (123456789 row)\n",
    "train_df = pd.read_csv(\"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\")\n",
    "val_df = pd.read_csv(\"E:/OCR_project/Datasets/archive/data_Set_converting/ValidateLabels.csv\")\n",
    "\n",
    "# Drop fake row (index 1 in your case)\n",
    "train_df = train_df.iloc[2:].reset_index(drop=True)\n",
    "val_df = val_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# Add full path to each image\n",
    "train_df[\"Image\"] = train_df[\"Image\"].apply(lambda x: os.path.join(train_images_path, x))\n",
    "val_df[\"Image\"] = val_df[\"Image\"].apply(lambda x: os.path.join(val_images_path, x))\n",
    "\n",
    "# Sort for consistency\n",
    "train_df = train_df.sort_values(\"Image\").reset_index(drop=True)\n",
    "val_df = val_df.sort_values(\"Image\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ec5a1",
   "metadata": {},
   "source": [
    "Extract Character Set and Max Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d3f85e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters: [' ', '\"', '#', '%', '(', ')', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', '_', '،', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي']\n",
      "Max text length: 109\n"
     ]
    }
   ],
   "source": [
    "# Get all unique characters in training set\n",
    "characters = set(char for text in train_df[\"Text\"] for char in text)\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "# Find maximum label length\n",
    "max_length = max(train_df[\"Text\"].apply(len))\n",
    "\n",
    "print(\"Unique characters:\", characters)\n",
    "print(\"Max text length:\", max_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e622443f",
   "metadata": {},
   "source": [
    "Prepare Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aec1d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_path = train_df[\"Image\"].values\n",
    "y_train = train_df[\"Text\"].values\n",
    "\n",
    "X_val_path = val_df[\"Image\"].values\n",
    "y_val = val_df[\"Text\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68197e88",
   "metadata": {},
   "source": [
    " Define Char Map for CTC  (Connectionist Temporal Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfae0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Character ↔ number mapping\n",
    "char_to_num = layers.StringLookup(vocabulary=characters, mask_token=None)\n",
    "num_to_char = layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ced1ee",
   "metadata": {},
   "source": [
    "Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d41b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_free_resize(image, img_size):\n",
    "    w, h = img_size\n",
    "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
    "    pad_height = h - tf.shape(image)[0]\n",
    "    pad_width = w - tf.shape(image)[1]\n",
    "\n",
    "    pad_height_top = pad_height // 2 + pad_height % 2\n",
    "    pad_height_bottom = pad_height // 2\n",
    "    pad_width_left = pad_width // 2 + pad_width % 2\n",
    "    pad_width_right = pad_width // 2\n",
    "\n",
    "    image = tf.pad(image, paddings=[\n",
    "        [pad_height_top, pad_height_bottom],\n",
    "        [pad_width_left, pad_width_right],\n",
    "        [0, 0],\n",
    "    ])\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    return image\n",
    "\n",
    "image_width = 2882\n",
    "image_height = 46\n",
    "padding_token = 99\n",
    "batch_size = 64\n",
    "\n",
    "def preprocess_image(image_path, img_size=(image_width, image_height)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=1)\n",
    "    image = distortion_free_resize(image, img_size)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "def vectorize_label(label):\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = 128 - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
    "    return label\n",
    "\n",
    "def process_images_labels(image_path, label):\n",
    "    image = preprocess_image(image_path)\n",
    "    label = vectorize_label(label)\n",
    "    return {\"image\": image, \"label\": label}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819232eb",
   "metadata": {},
   "source": [
    "Create Datasets by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "188685f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(image_paths, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(process_images_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = prepare_dataset(X_train_path, y_train)\n",
    "validation_ds = prepare_dataset(X_val_path, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733fd8b",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b95aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Custom CTC Layer\n",
    "class CTCLayer(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        return y_pred  # At test time, just return predictions\n",
    "\n",
    "# Build Model Function\n",
    "def build_model():\n",
    "    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n",
    "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
    "\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"Conv1\")(input_img)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    new_shape = ((image_width // 2), (image_height // 2) * 64)\n",
    "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "\n",
    "    x = keras.layers.Dense(16, activation=\"relu\", name=\"dense2\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(128, return_sequences=True, dropout=0.35)\n",
    "    )(x)\n",
    "\n",
    "    x = keras.layers.Dense(\n",
    "        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense3\"\n",
    "    )(x)\n",
    "\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input_img, labels], outputs=output, name=\"Arabic_OCR\")\n",
    "\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.0001,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9\n",
    "    )\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# Edit Distance Calculation Function\n",
    "def calculate_edit_distance(labels, predictions):\n",
    "    sparse_labels = tf.sparse.from_dense(labels)\n",
    "\n",
    "    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n",
    "\n",
    "    decoded_preds = keras.backend.ctc_decode(\n",
    "        predictions, input_length=input_len, greedy=False, beam_width=100\n",
    "    )[0][0][:, :max_length]\n",
    "\n",
    "    sparse_preds = tf.sparse.from_dense(decoded_preds)\n",
    "\n",
    "    edit_distances = tf.edit_distance(sparse_preds, sparse_labels, normalize=False)\n",
    "    return tf.reduce_mean(edit_distances)\n",
    "\n",
    "# Custom Callback to Print Edit Distance\n",
    "class EditDistanceCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, pred_model):\n",
    "        super().__init__()\n",
    "        self.prediction_model = pred_model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        edit_distances = []\n",
    "\n",
    "        for i in range(len(validation_images)):\n",
    "            labels = validation_labels[i]\n",
    "            predictions = self.prediction_model.predict(validation_images[i])\n",
    "            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n",
    "\n",
    "        print(f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47cb7cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n",
      "Conv1\n",
      "pool1\n",
      "batch_normalization_10\n",
      "reshape\n",
      "dense2\n",
      "batch_normalization_11\n",
      "bidirectional_5\n",
      "label\n",
      "dense3\n",
      "ctc_loss\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85d67854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\nNewRandomAccessFile failed to Create/Open: E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed/AHTD3A0001_Para2_1laaa.jpg : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_21592]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m edit_distance_callback \u001b[38;5;241m=\u001b[39m EditDistanceCallback(prediction_model)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 4. Train the model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43medit_distance_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\nNewRandomAccessFile failed to Create/Open: E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed/AHTD3A0001_Para2_1laaa.jpg : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_21592]"
     ]
    }
   ],
   "source": [
    "# 1. Build the model\n",
    "model = build_model()\n",
    "\n",
    "# 2. Extract prediction model from the full model (before CTCLayer)\n",
    "# CTCLayer is the final output, so we skip it in prediction\n",
    "# prediction_model = keras.models.Model(\n",
    "#     model.get_layer(name=\"image\").input,  # ✅ This is the input layer\n",
    "#     model.get_layer(name=\"dense3\").output # ✅ This is the layer before CTCLayer\n",
    "# )\n",
    "prediction_model = keras.models.Model(\n",
    "    model.input,\n",
    "    model.get_layer(name=\"dense3\").output\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Create the custom callback\n",
    "edit_distance_callback = EditDistanceCallback(prediction_model)\n",
    "\n",
    "# 4. Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[edit_distance_callback],\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdbf4042",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m missing_files \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(IMG_DIR, x)))]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal missing images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(missing_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(missing_files\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "missing_files = df[~df[\"filename\"].apply(lambda x: os.path.exists(os.path.join(IMG_DIR, x)))]\n",
    "print(f\"Total missing images: {len(missing_files)}\")\n",
    "print(missing_files.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f243fe",
   "metadata": {},
   "source": [
    "fixing problem why can`t see images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cfd87",
   "metadata": {},
   "source": [
    "| Issue                                                        | Fix                                             |\n",
    "| ------------------------------------------------------------ | ----------------------------------------------- |\n",
    "| Extra spaces in filename                                     | Strip whitespace: `x.strip()`                   |\n",
    "| Wrong case (Windows is case-insensitive, but safer to check) | Ensure file names are exact                     |\n",
    "| Wrong column name                                            | Confirm `Image` column has the filenames        |\n",
    "| Double slashes or backslashes                                | Use `os.path.join()` instead of manual paths    |\n",
    "| Encoding issues from CSV                                     | Open CSV in `utf-8` or `windows-1256` if Arabic |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4197dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Total missing image files: 1901\n",
      "                    Image                                               Text\n",
      "0                       0                                          123456789\n",
      "1  AHTD3A0001_Para1_3.jpg  طفنا وسعينا مع شيخ. كان جاري في الخيم يتكلم وه...\n",
      "2  AHTD3A0005_Para1_1.jpg  ذهب نوح مظفر ضرغام بصح ب رؤوف بن لؤي رايق ظافر...\n",
      "3  AHTD3A0005_Para1_2.jpg  بدأت قوافل الحجيج حاج اثر اخر يلبي. عند وصولنا...\n",
      "4  AHTD3A0005_Para1_3.jpg  يتكلم وهو نائم  بكلمات لا أفهمها مثل انقض بغلس...\n",
      "5  AHTD3A0047_Para1_1.jpg  ذهب نوح مظفر ضرغام بصحب رؤوف بن لؤي رايق ظافر ...\n",
      "6  AHTD3A0047_Para1_2.jpg  بدأت قوافل الحجيج حاج إثر آخر يلبي عند وصولنا ...\n",
      "7  AHTD3A0047_Para1_3.jpg  يتكلم في الخيم يتكلم وهو نائم  بكلمات لا أفهمه...\n",
      "8  AHTD3A0047_Para1_4.jpg  راجح هل بلغ أصحابنا ظ ع ك  ث خ ض ب س ش ص غ ه أ...\n",
      "9  AHTD3A0047_Para1_5.jpg  الكلمات التالي لهذا النص مشمش دراق غيظ ناء   ب...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set image directory and load CSV\n",
    "IMG_DIR = \"E:/OCR_project/Datasets/archive/Train_deskewed/Train_deskewed\"\n",
    "csv_path = \"E:/OCR_project/Datasets/archive/data_Set_converting/TrainLabels.csv\"  # Adjust if needed\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Find missing files\n",
    "missing_files = df[~df[\"Image\"].apply(lambda x: os.path.exists(os.path.join(IMG_DIR, x)))]\n",
    "\n",
    "# Print report\n",
    "print(f\"❌ Total missing image files: {len(missing_files)}\")\n",
    "print(missing_files.head(10))  # Show first 10 missing\n",
    "\n",
    "# Optional: Save list of missing to a CSV file for review\n",
    "missing_files.to_csv(\"missing_files_report.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e8d629f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image    1901\n",
       "Text     1901\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
